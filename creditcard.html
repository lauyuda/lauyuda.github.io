<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Credit Card Project</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Lau Yu Da</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Portfolio</a></li>
							<li class="active"><a href="creditcard.html.html">Credit Card Fraud</a></li>
							<li><a href="certifications.html">Certifications</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/lauyuda/" target="_blank" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/lauyuda" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">Work in progress</span>
									<h1>Credit Card Fraud<br />
									</h1>
									<p>Using dataset from Kaggle.com<br />
									and applying machine learning concepts<br />
									to sieve out fraudulent transactions.</p>
								</header>
								<div class="image main"><img src="images/creditcard.png" alt="" /></div>
								<p>We will first look at how we can measure the performance of the model and the types of models 
									suitable for an imbalanced dataset. The first part will explore different options available 
									in detecting the fraudulent credit card transactions.
								</p>
								<h2>Performance Measures</h2>
								<h3>Confusion Matrix-based Evaluation</h3>
									<dl>
										<dt>Accuracy</dt>
										<dd>
											<p>Accuracy is not the best way to measure the performance of a machine learning model for an
												imbalanced dataset. For example, if a dataset only has 0.1% fraud data, blindly labeling 
												every data point as fraud will yield 99.9% accuracy. Other metrics should be used to 
												paint a better picture of the actual performance.
											</p>
										</dd>
										<dt>Recall</dt>
										<dd>
											<p>To ensure that no fraudulent transaction get misidentified as non-fraudulent, the recall 
												can be maximised. This is an interesting metric that can be used. However, there will 
												be a trade-off between recall and precision.
											</p>
										</dd>
										<dt>F1 Score</dt>
										<dd>
											<p>To address the trade-off mentioned earlier, the F1 score was devised to calculate the 
												harmonic mean between precision and recall and therefore gives equal importance
												to precision and recall.</p>
										</dd>
									</dl>
								<h3>Parametric Evaluation</h3>
									<dl>
										<dt>ROC Curve</dt>
										<dd>
											<p>The axes consists of true positive rate (i.e. recall) for the y-axis and
												false positive rate for the x-axis. Both axes are proportion of the class they
												are representing: positive for the true positive rate and negative for the
												false positive rate. Therefore, the ROC curve is insensitive to unbalanced
												datasets.
											</p>
										</dd>
										<dt>Precision-Recall Curve</dt>
										<dd>
											<p>The precision-recall curve shows the tradeoff between precision and recall for 
												different threshold. A high area under the curve represents both high recall 
												and high precision, where high precision relates to a low false positive rate, 
												and high recall relates to a low false negative rate.
											</p>
										</dd>
									</dl>
								<h2>Methods</h2>
								<h3>Sampling</h3>
									<dl>
										<dt>Undersampling</dt>
										<dd>
											<p>Undersampling consists in rebalancing the dataset by taking less examples from 
												the majority class in order to match the absolute number of examples of the 
												minority class. This can potentially lead to loss of information. But if the 
												examples of the majority class are near to others, this method might yield 
												good results.
											</p>
										</dd>
										<dt>Oversampling</dt>
										<dd>
											<p>Oversampling is upsampling the minority class to make it equal in size to the 
												majority class. The problem is where and how to generate these new points. 
												This may lead to overfitting as the points generated may not be true 
												representatives of the actual minority class.
											</p>
										</dd>
									</dl>
								<h3>Model-based</h3>
									<dl>
										<dt>Isolation Forest</dt>
										<dd>
											<p>Isolating anomaly observations is easier because only a few conditions are needed 
												to separate those cases from the normal observations. On the other hand, isolating 
												normal observations require more conditions. Therefore, an anomaly score can be 
												calculated as the number of conditions required to separate a given observation.

											</p>
										</dd>
										<dt>Local Outlier Factor</dt>
										<dd>
											<p>This algorithm is an unsupervised outlier detection method which computes the 
												local density deviation of a given data point with respect to its neighbors. It 
												considers as outlier samples that have a substantially lower density than their 
												neighbors.
											</p>
										</dd>
									</dl>
								<h2>Results</h2>
								<h3>Without Undersampling</h3>
								<p><span class="image left"><img src="images/classimbalance.png" alt="" /></span>
									The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.
									Out of 284,807 transactions, there are only 492 fraud cases. For computational purposes,
									only 10% of the data will be used but the percentage of frauds will remain the same.
								</p>
								<br>
								<h4>Grid Search</h3>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Rank</th>
													<th>Mean</th>
													<th>Std Dev</th>
													<th>max_depth</th>
													<th>n_estimators</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>1</td>
													<td>0.699</td>
													<td>0.194</td>
													<td>3</td>
													<td>20</td>
												</tr>
												<tr>
													<td>2</td>
													<td>0.541</td>
													<td>0.286</td>
													<td>5</td>
													<td>1000</td>
												</tr>
												<tr>
													<td>3</td>
													<td>0.526</td>
													<td>0.273</td>
													<td>3</td>
													<td>1000</td>
												</tr>
												<tr>
													<td>4</td>
													<td>0.521</td>
													<td>0.274</td>
													<td>3</td>
													<td>180</td>
												</tr>
												<tr>
													<td>5</td>
													<td>0.501</td>
													<td>0.238</td>
													<td>5</td>
													<td>180</td>
												</tr>
											</tbody>
										</table>
									</div>
								<p><span class="image right"><img src="images/confusionmatrix1.png" alt="" /></span>
									<br> A grid search was ran over some possible scenarios using recall as the scoring and the 
									top five were recorded in a table. A confusion matrix was plotted and out of the actual 
									frauds, 27% of them were misidentified as non-fraudulent.
								</p>
								<h3>Undersampling</h3>
								<p><span class="image left"><img src="images/undersampling.png" alt="" /></span>
									In this technique, majority class was undersampled to match the minority class. 
									Random sample of non-fraud class were taken to match number of fraud samples. 
									This makes sure that the training data has equal amount of fraud and non-fraud samples
									such that the ratio is 1:1.
								</p>
								<br>
								<h4>Grid Search</h3>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Rank</th>
													<th>Mean</th>
													<th>Std Dev</th>
													<th>max_depth</th>
													<th>n_estimators</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>1</td>
													<td>0.940</td>
													<td>0.0256</td>
													<td>3</td>
													<td>180</td>
												</tr>
												<tr>
													<td>2</td>
													<td>0.940</td>
													<td>0.0274</td>
													<td>3</td>
													<td>1000</td>
												</tr>
												<tr>
													<td>3</td>
													<td>0.937</td>
													<td>0.0277</td>
													<td>3</td>
													<td>20</td>
												</tr>
												<tr>
													<td>4</td>
													<td>0.936</td>
													<td>0.0286</td>
													<td>2</td>
													<td>180</td>
												</tr>
												<tr>
													<td>5</td>
													<td>0.934</td>
													<td>0.0220</td>
													<td>5</td>
													<td>180</td>
												</tr>
											</tbody>
										</table>
									</div>
								<p><span class="image right"><img src="images/confusionmatrix2.png" alt="" /></span>
									This time, accuracy scoring was used to run a grid search and the top five were tabulated.
									A confusion matrix was plotted and out of the actual frauds, only 7% of them were misidentified
									as non-fraudulent, much better than the previous. 
								</p>
								<p>However, there is also an increase in false
									positives. This means that there is a balance between better customer experience and better 
									fraud detection.
								</p>
								<h3>Outlier Detection Models</h3>
								<p>Without having to undersample, even with an imbalanced dataset, there are models that can 
									detect these fraud cases. In this example, isolation forest and local outlier detection 
									will be explored. The isolation forest model is based on decision trees while the local 
									outlier detection is based on k-nearest-neighbour.
								</p>
								<h4>Isolation Forest</h3>
									<p>Number of errors: 71
										<br>Accuracy: 0.998</p>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Class</th>
													<th>Precision</th>
													<th>Recall</th>
													<th>F1 Score</th>
													<th>Support</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>0</td>
													<td>1.00</td>
													<td>1.00</td>
													<td>1.00</td>
													<td>28432</td>
												</tr>
												<tr>
													<td>1</td>
													<td>0.28</td>
													<td>0.29</td>
													<td>0.28</td>
													<td>49</td>
												</tr>
											</tbody>
										</table>
									</div>
								
								<h4>Local Outlier Factor</h4>
									<p>Number of errors: 97
										<br>Accuracy: 0.997</p>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Class</th>
													<th>Precision</th>
													<th>Recall</th>
													<th>F1 Score</th>
													<th>Support</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>0</td>
													<td>1.00</td>
													<td>1.00</td>
													<td>1.00</td>
													<td>28432</td>
												</tr>
												<tr>
													<td>1</td>
													<td>0.02</td>
													<td>0.02</td>
													<td>0.02</td>
													<td>49</td>
												</tr>
											</tbody>
										</table>
									</div>

							</section>
							<section>
								<p>Click <a href="https://github.com/lauyuda/creditcard/blob/main/CreditCard.ipynb" target="_blank">here</a> to see code on Github.</p>
								<p><a href="index.html">Go back.</a></p>
							</section>
					</div>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>